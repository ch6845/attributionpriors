{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import functools\n",
    "import operator\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEFAULT_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def gather_nd(params, indices):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        params: Tensor to index\n",
    "        indices: k-dimension tensor of integers. \n",
    "    Returns:\n",
    "        output: 1-dimensional tensor of elements of ``params``, where\n",
    "            output[i] = params[i][indices[i]]\n",
    "\n",
    "            params   indices   output\n",
    "\n",
    "            1 2       1 1       4\n",
    "            3 4       2 0 ----> 5\n",
    "            5 6       0 0       1\n",
    "    \"\"\"\n",
    "    max_value = functools.reduce(operator.mul, list(params.size())) - 1\n",
    "    indices = indices.t().long()\n",
    "    ndim = indices.size(0)\n",
    "    idx = torch.zeros_like(indices[0]).long()\n",
    "    m = 1\n",
    "\n",
    "    for i in range(ndim)[::-1]:\n",
    "        idx += indices[i]*m\n",
    "        m *= params.size(i)\n",
    "\n",
    "    idx[idx < 0] = 0\n",
    "    idx[idx > max_value] = 0\n",
    "    return torch.take(params, idx)\n",
    "    \n",
    "\n",
    "class AttributionPriorExplainer(object):\n",
    "    def __init__(self, background_dataset, batch_size, random_alpha=True,k=1,scale_by_inputs=True):\n",
    "        self.random_alpha = random_alpha\n",
    "        self.k = k\n",
    "        self.scale_by_inputs = scale_by_inputs\n",
    "        self.batch_size = batch_size\n",
    "        self.ref_set = background_dataset\n",
    "        self.ref_sampler = DataLoader(\n",
    "                dataset=background_dataset, \n",
    "                batch_size=batch_size*k, \n",
    "                shuffle=True, \n",
    "                drop_last=True)\n",
    "        return\n",
    "\n",
    "    def _get_ref_batch(self,k=None):\n",
    "        return next(iter(self.ref_sampler))[0].float()\n",
    "    \n",
    "    def _get_samples_input(self, input_tensor, reference_tensor):\n",
    "        '''\n",
    "        calculate interpolation points\n",
    "        Args:\n",
    "            input_tensor: Tensor of shape (batch, ...), where ... indicates\n",
    "                          the input dimensions. \n",
    "            reference_tensor: A tensor of shape (batch, k, ...) where ... \n",
    "                indicates dimensions, and k represents the number of background \n",
    "                reference samples to draw per input in the batch.\n",
    "        Returns: \n",
    "            samples_input: A tensor of shape (batch, k, ...) with the \n",
    "                interpolated points between input and ref.\n",
    "        '''\n",
    "        input_dims = list(input_tensor.size())[1:]\n",
    "        num_input_dims = len(input_dims)\n",
    "            \n",
    "        batch_size = reference_tensor.size()[0]\n",
    "        k_ = reference_tensor.size()[1]\n",
    "\n",
    "        # Grab a [batch_size, k]-sized interpolation sample\n",
    "        if self.random_alpha:\n",
    "            t_tensor = torch.FloatTensor(batch_size, k_).uniform_(0,1).to(DEFAULT_DEVICE)\n",
    "        else:\n",
    "            if k_==1:\n",
    "                t_tensor = torch.cat([torch.Tensor([1.0]) for i in range(batch_size)]).to(DEFAULT_DEVICE)\n",
    "            else:\n",
    "                t_tensor = torch.cat([torch.linspace(0,1,k_) for i in range(batch_size)]).to(DEFAULT_DEVICE)\n",
    "\n",
    "        shape = [batch_size, k_] + [1] * num_input_dims\n",
    "        interp_coef = t_tensor.view(*shape)\n",
    "\n",
    "        # Evaluate the end points\n",
    "        end_point_ref = (1.0 - interp_coef) * reference_tensor\n",
    "\n",
    "        input_expand_mult = input_tensor.unsqueeze(1)\n",
    "        end_point_input = interp_coef * input_expand_mult\n",
    "        \n",
    "        # A fine Affine Combine\n",
    "        samples_input = end_point_input + end_point_ref\n",
    "        return samples_input\n",
    "    \n",
    "    def _get_samples_delta(self, input_tensor, reference_tensor):\n",
    "        input_expand_mult = input_tensor.unsqueeze(1)\n",
    "        sd = input_expand_mult - reference_tensor\n",
    "        return sd\n",
    "    \n",
    "    def _get_grads(self, samples_input, model, sparse_labels=None):\n",
    "        samples_input.requires_grad = True\n",
    "\n",
    "        grad_tensor = torch.zeros(samples_input.shape).float().to(DEFAULT_DEVICE)\n",
    "\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            particular_slice = samples_input[:,i]\n",
    "            batch_output = model(particular_slice)\n",
    "            # should check that users pass in sparse labels\n",
    "            # Only look at the user-specified label\n",
    "            if batch_output.size(1) > 1:\n",
    "                sample_indices = torch.arange(0,batch_output.size(0)).to(DEFAULT_DEVICE)\n",
    "                indices_tensor = torch.cat([\n",
    "                        sample_indices.unsqueeze(1), \n",
    "                        sparse_labels.unsqueeze(1)], dim=1)\n",
    "                batch_output = gather_nd(batch_output, indices_tensor)\n",
    "\n",
    "            model_grads = grad(\n",
    "                    outputs=batch_output,\n",
    "                    inputs=particular_slice,\n",
    "                    grad_outputs=torch.ones_like(batch_output).to(DEFAULT_DEVICE),\n",
    "                    create_graph=True)\n",
    "            grad_tensor[:,i,:] = model_grads[0]\n",
    "        return grad_tensor\n",
    "           \n",
    "    def shap_values(self, model, input_tensor, sparse_labels=None):\n",
    "        \"\"\"\n",
    "        Calculate expected gradients approximation of Shapley values for the \n",
    "        sample ``input_tensor``.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Pytorch neural network model for which the\n",
    "                output should be explained.\n",
    "            input_tensor (torch.Tensor): Pytorch tensor representing the input\n",
    "                to be explained.\n",
    "            sparse_labels (optional, default=None): \n",
    "        \"\"\"\n",
    "        reference_tensor = self._get_ref_batch()\n",
    "        shape = reference_tensor.shape\n",
    "        reference_tensor = reference_tensor.view(\n",
    "                self.batch_size, \n",
    "                self.k, \n",
    "                *(shape[1:])).to(DEFAULT_DEVICE)\n",
    "        samples_input = self._get_samples_input(input_tensor, reference_tensor)\n",
    "        samples_delta = self._get_samples_delta(input_tensor, reference_tensor)\n",
    "        grad_tensor = self._get_grads(samples_input, model, sparse_labels)\n",
    "        mult_grads = samples_delta * grad_tensor if self.scale_by_inputs else grad_tensor\n",
    "        expected_grads = mult_grads.mean(1)\n",
    "        return expected_grads\n",
    "\n",
    "class VariableBatchExplainer(AttributionPriorExplainer):\n",
    "    \"\"\"\n",
    "    Subclasses AttributionPriorExplainer to avoid pre-specified batch size. Will adapt batch\n",
    "    size based on shape of input tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, background_dataset, random_alpha=True,scale_by_inputs=True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        background_dataset: PyTorch dataset - may not work with iterable-type (vs map-type) datasets\n",
    "        random_alpha: boolean - Whether references should be interpolated randomly (True, corresponds\n",
    "            to Expected Gradients) or on a uniform grid (False - corresponds to Integrated Gradients)\n",
    "        \"\"\"\n",
    "        self.random_alpha = random_alpha\n",
    "        self.k = None\n",
    "        self.scale_by_inputs=scale_by_inputs\n",
    "        self.ref_set = background_dataset\n",
    "        self.ref_sampler = DataLoader(\n",
    "                dataset=background_dataset, \n",
    "                batch_size=1, \n",
    "                shuffle=True, \n",
    "                drop_last=True)\n",
    "        self.refs_needed = -1\n",
    "        return\n",
    "\n",
    "    def _get_ref_batch(self,refs_needed=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        refs_needed: int - number of references to provide\n",
    "        \"\"\"\n",
    "        if refs_needed!=self.refs_needed:\n",
    "            self.ref_sampler = DataLoader(\n",
    "                dataset=self.ref_set, \n",
    "                batch_size=refs_needed, \n",
    "                shuffle=True, \n",
    "                drop_last=True)\n",
    "            self.refs_needed = refs_needed\n",
    "        return next(iter(self.ref_sampler))[0].float()\n",
    "           \n",
    "    def shap_values(self, model, input_tensor, sparse_labels=None,k=1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        base_model: PyTorch network\n",
    "        input_tensor: PyTorch tensor to get attributions for, as in normal torch.nn.Module API\n",
    "        sparse_labels:  np.array of sparse integer labels, i.e. 0-9 for MNIST. Used if you only\n",
    "            want to explain the prediction for the true class per sample.\n",
    "        k: int - Number of references to use default for explanations. As low as 1 for training.\n",
    "            100-200 for reliable explanations. \n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        n_input = input_tensor.shape[0]\n",
    "        refs_needed = n_input*self.k\n",
    "        # This is a reasonable check but prevents compatibility with non-Map datasets\n",
    "        assert refs_needed<=len(self.ref_set), \"Can't have more samples*references than there are reference points!\"\n",
    "        reference_tensor = self._get_ref_batch(refs_needed)\n",
    "        shape = reference_tensor.shape\n",
    "        reference_tensor = reference_tensor.view(\n",
    "                n_input, \n",
    "                self.k,\n",
    "                *(shape[1:])).to(DEFAULT_DEVICE)\n",
    "        samples_input = self._get_samples_input(input_tensor, reference_tensor)\n",
    "        samples_delta = self._get_samples_delta(input_tensor, reference_tensor)\n",
    "        grad_tensor = self._get_grads(samples_input, model, sparse_labels)\n",
    "        mult_grads = samples_delta * grad_tensor if self.scale_by_inputs else grad_tensor\n",
    "        expected_grads = mult_grads.mean(1)\n",
    "\n",
    "        return expected_grads\n",
    "\n",
    "class ExpectedGradientsModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wraps a PyTorch model (one that implements torch.nn.Module) so that model(x)\n",
    "    produces SHAP values as well as predictions (controllable by 'shap_values'\n",
    "    flag.\n",
    "    \"\"\"\n",
    "    def __init__(self,base_model,refset,k=1,random_alpha=True,scale_by_inputs=True):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        base_model: PyTorch network that subclasses torch.nn.Module\n",
    "        refset: PyTorch dataset - may not work with iterable-type (vs map-type) datasets\n",
    "        k: int - Number of references to use by default for explanations. As low as 1 for training.\n",
    "            100-200 for reliable explanations. \n",
    "        \"\"\"\n",
    "        super(ExpectedGradientsModel,self).__init__()\n",
    "        self.k = k\n",
    "        self.base = base_model\n",
    "        self.refset = refset\n",
    "        self.random_alpha = random_alpha\n",
    "        self.exp = VariableBatchExplainer(self.refset,random_alpha=random_alpha,scale_by_inputs=scale_by_inputs)\n",
    "    def forward(self,x,shap_values=False,sparse_labels=None,k=1):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        x: PyTorch tensor to predict with, as in normal torch.nn.Module API\n",
    "        shap_values:     Binary flag -- whether to produce SHAP values\n",
    "        sparse_labels:  np.array of sparse integer labels, i.e. 0-9 for MNIST. Used if you only\n",
    "            want to explain the prediction for the true class per sample.\n",
    "        k: int - Number of references to use default for explanations. As low as 1 for training.\n",
    "            100-200 for reliable explanations. \n",
    "        \"\"\"\n",
    "        output = self.base(x)\n",
    "        if not shap_values: return output\n",
    "        else: shaps = self.exp.shap_values(self.base,x,sparse_labels=sparse_labels,k=k)\n",
    "        return output, shaps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MarcoPolo",
   "language": "python",
   "name": "marcopolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
